{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMw3Xq5izjoN1uPBhbJqHUt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-maekakuchi/tabelog_scraping/blob/main/tabelog_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ライブラリのインストール\n",
        "!pip install beautifulsoup4 pandas gspread gspread_dataframe\n",
        "\n",
        "\n",
        "# 認証のためのコード\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "prefecture = \"青森県\"   # 取得したい都道府県名を入力してください。\n",
        "file_id = \"1m_WEhidFawgTiIqVvur7sKd0LmXx0pyw\"   # 実行ファイルのファイルIDを入力してください。\n",
        "\n",
        "prefecture_arr = { \n",
        "  \"北海道\": \"hokkaido\",\n",
        "  \"青森県\": \"aomori\",\n",
        "  \"岩手県\": \"iwate\",\n",
        "  \"宮城県\": \"miyagi\",\n",
        "  \"秋田県\": \"akita\",\n",
        "  \"山形県\": \"yamagata\",\n",
        "  \"福島県\": \"fukushima\",\n",
        "  \"茨城県\": \"ibaraki\",\n",
        "  \"栃木県\": \"tochigi\",\n",
        "  \"群馬県\": \"gunma\",\n",
        "  \"埼玉県\": \"saitama\",\n",
        "  \"千葉県\": \"chiba\",\n",
        "  \"東京都\": \"tokyo\",\n",
        "  \"神奈川県\": \"kanagawa\",\n",
        "  \"新潟県\": \"niigata\",\n",
        "  \"富山県\": \"toyama\",\n",
        "  \"石川県\": \"ishikawa\",\n",
        "  \"福井県\": \"fukui\",\n",
        "  \"山梨県\": \"yamanashi\",\n",
        "  \"長野県\": \"nagano\",\n",
        "  \"岐阜県\": \"gifu\",\n",
        "  \"静岡県\": \"shizuoka\",\n",
        "  \"愛知県\": \"aichi\",\n",
        "  \"三重県\": \"mie\",\n",
        "  \"滋賀県\": \"shiga\",\n",
        "  \"京都府\": \"kyoto\",\n",
        "  \"大阪府\": \"osaka\",\n",
        "  \"兵庫県\": \"hyogo\",\n",
        "  \"奈良県\": \"nara\",\n",
        "  \"和歌山県\": \"wakayama\",\n",
        "  \"鳥取県\": \"tottori\",\n",
        "  \"島根県\": \"shimane\",\n",
        "  \"岡山県\": \"okayama\",\n",
        "  \"広島県\": \"hiroshima\",\n",
        "  \"山口県\": \"yamaguchi\",\n",
        "  \"徳島県\": \"tokushima\",\n",
        "  \"香川県\": \"kagawa\",\n",
        "  \"愛媛県\": \"ehime\",\n",
        "  \"高知県\": \"kochi\",\n",
        "  \"福岡県\": \"fukuoka\",\n",
        "  \"佐賀県\": \"saga\",\n",
        "  \"長崎県\": \"nagasaki\",\n",
        "  \"熊本県\": \"kumamoto\",\n",
        "  \"大分県\": \"oita\",\n",
        "  \"宮崎県\": \"miyazaki\",\n",
        "  \"鹿児島県\": \"kagoshima\",\n",
        "  \"沖縄県\": \"okinawa\"\n",
        "}\n",
        "prefecture_eng = prefecture_arr[prefecture]\n",
        "\n",
        "\n",
        "# スプレッドシートの作成\n",
        "import datetime\n",
        "from googleapiclient.discovery import build\n",
        "today = datetime.date.today().strftime('%Y%m%d')\n",
        "sh_name = '飲食店リスト_' + prefecture + '_' + today\n",
        "client = gspread.Client(auth = creds)\n",
        "sh = client.create(sh_name)\n",
        "\n",
        "\n",
        "# フォルダーの変更\n",
        "service = build(\"drive\", \"v3\")\n",
        "\n",
        "def getFolderID(file_id):\n",
        "  file = service.files().get(fileId = file_id, fields = \"parents\").execute()\n",
        "  return file[\"parents\"][0]\n",
        "\n",
        "sh_file_id = sh.id                              # 生成されたスプレッドシートのファイルID\n",
        "pre_folder_id = getFolderID(sh_file_id)         # 生成されたスプレッドシートがあるルートディレクトリのID\n",
        "folder_id = getFolderID(file_id)                # 実行ファイルのフォルダID\n",
        "\n",
        "service.files().update(\n",
        "  fileId = sh_file_id,\n",
        "  removeParents = pre_folder_id,\n",
        "  addParents = folder_id\n",
        ").execute()\n",
        "\n",
        "\n",
        "# タイトル列を設定\n",
        "worksheet = sh.get_worksheet(0)\n",
        "column_title = [[\n",
        "  '店名', \n",
        "  'ジャンル', \n",
        "  '住所', \n",
        "  '点数', \n",
        "  '価格帯（ディナー）', \n",
        "  '価格帯（ランチ）', \n",
        "  'コース', \n",
        "  '営業時間', \n",
        "  '定休日', \n",
        "  '喫煙可否', \n",
        "  '喫煙可否詳細', \n",
        "  '店舗URL', \n",
        "  '電話番号'\n",
        "]]\n",
        "worksheet.append_rows(column_title)\n",
        "worksheet.format(\"A1:Z100\", {'horizontalAlignment': 'center', 'verticalAlignment': 'middle'})\n",
        "\n",
        "\n",
        "# Webスクレイピング\n",
        "import requests\n",
        "import re\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def fetchHtml(url):\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  return soup\n",
        "  \n",
        "def extractData(page_link):\n",
        "  soup = fetchHtml(page_link)\n",
        "\n",
        "  shops = soup.find_all(\"a\", class_=\"list-rst__rst-name-target cpy-rst-name\")    # ページ内の店舗のaタグを取得\n",
        "  for shop in shops:\n",
        "    extracted_data = [[]]     # 店舗毎の抽出データを格納する二次元配列\n",
        "    shop_name      = \"\"\n",
        "    shop_link      = \"\"\n",
        "    genre          = \"\"\n",
        "    address        = \"\"\n",
        "    score          = \"\"\n",
        "    price_dinner   = \"\"\n",
        "    price_lunch    = \"\"\n",
        "    course         = \"-\"\n",
        "    open_hour      = \"\"\n",
        "    smoking        = \"\"\n",
        "    smoking_detail = \"\"\n",
        "    holiday        = \"\"\n",
        "    tel            = \"\"\n",
        "\n",
        "    # 店名\n",
        "    shop_name = shop.text\n",
        "    extracted_data[0].append(shop_name)\n",
        "\n",
        "    # aタグのhref属性にアクセス\n",
        "    shop_link = shop[\"href\"]\n",
        "    soup = fetchHtml(shop_link)\n",
        "\n",
        "    detail_tables = soup.find_all('table', class_='c-table c-table--form rstinfo-table__table')\n",
        "\n",
        "    # ジャンル\n",
        "    for table in detail_tables:\n",
        "        th = table.find('th', string='ジャンル')\n",
        "        if th:\n",
        "            genre = th.find_next('td').text\n",
        "    extracted_data[0].append(genre)\n",
        "\n",
        "    # 住所\n",
        "    addresses = soup.find(class_='rstinfo-table__address')\n",
        "    for addr in addresses.find_all('span'):\n",
        "      address += addr.text\n",
        "    extracted_data[0].append(address)\n",
        "\n",
        "    # 点数\n",
        "    score = soup.find(class_='rdheader-rating__score-val-dtl').text\n",
        "    extracted_data[0].append(score)\n",
        "\n",
        "    # 価格帯\n",
        "    prices = soup.find_all(class_='rdheader-budget__price-target')\n",
        "    price_dinner = prices[0].text\n",
        "    price_lunch = prices[1].text\n",
        "    extracted_data[0].append(price_dinner)\n",
        "    extracted_data[0].append(price_lunch)\n",
        "\n",
        "    # コース\n",
        "    for table in detail_tables:\n",
        "      th = table.find('th', string='コース')\n",
        "      if th:\n",
        "        course = th.find_next('td').text\n",
        "    extracted_data[0].append(course)\n",
        "\n",
        "    # 営業時間と定休日\n",
        "    for table in detail_tables:\n",
        "      th = table.find('th', string='営業時間')\n",
        "      if th:\n",
        "        open_hours = th.find_next('td')\n",
        "        if open_hours.find_all(\"br\"):\n",
        "          for br in open_hours.find_all(\"br\"):\n",
        "            br.replace_with(\"\\n\")\n",
        "        open_hours = open_hours.text\n",
        "        open_hour = open_hours.split(\"定休日\")[0]\n",
        "        open_hour = open_hour.replace('営業時間', '')\n",
        "        holiday = open_hours.split(\"定休日\")[1]\n",
        "    extracted_data[0].append(open_hour)\n",
        "    extracted_data[0].append(holiday)\n",
        "\n",
        "    # 喫煙可否と詳細\n",
        "    for table in detail_tables:\n",
        "      th = table.find('th', string='禁煙・喫煙')\n",
        "      if th:\n",
        "        smoking = th.find_next('td').text\n",
        "        smoking_arr = smoking.splitlines()\n",
        "        if smoking_arr[0] == \"\":\n",
        "          smoking_arr.pop(0)\n",
        "        \n",
        "        smoking = smoking_arr[0]\n",
        "        if ('禁煙' in smoking):\n",
        "          smoking = '×'\n",
        "        elif ('喫煙' in smoking or '分煙' in smoking):\n",
        "          smoking = '〇'\n",
        "        else:\n",
        "          smoking = '-'\n",
        "        \n",
        "        smoking_len = len(smoking_arr)\n",
        "        if smoking_len >= 2:\n",
        "          for i, _smoking in enumerate(smoking_arr):\n",
        "            smoking_detail += _smoking\n",
        "            if i != smoking_len - 1:\n",
        "              smoking_detail += os.linesep\n",
        "        else:\n",
        "          smoking_detail = \"-\"\n",
        "    extracted_data[0].append(smoking)\n",
        "    extracted_data[0].append(smoking_detail)\n",
        "\n",
        "    # 店舗URL\n",
        "    extracted_data[0].append(shop_link)\n",
        "\n",
        "    # 電話番号\n",
        "    for table in detail_tables:\n",
        "      for th in soup.find_all(\"th\"):\n",
        "        if th and \"予約\" in th.text and \"お問い合わせ\" in th.text:\n",
        "          tel = th.find_next('td').text\n",
        "    extracted_data[0].append(tel)\n",
        "\n",
        "    # スプレッドシートに書き込み\n",
        "    worksheet.append_rows(extracted_data)\n",
        "\n",
        "\n",
        "\n",
        "# 指定した都道府県のurl\n",
        "url = \"https://tabelog.com/\" + prefecture_eng + \"/rstLst/cond04-00-07/\"\n",
        "soup = fetchHtml(url)\n",
        "\n",
        "pages = soup.find_all(\"a\", class_=\"c-pagination__num\")  # 複数ページある場合、ページのaタグを取得\n",
        "if pages:\n",
        "  for page in pages:\n",
        "    extractData(page[\"href\"])\n",
        "else:\n",
        "  extractData(url)"
      ],
      "metadata": {
        "id": "21pTPig9nwEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca69480f-f6b4-4691-8bc6-9163e97a23b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (4.6.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.8/dist-packages (3.4.2)\n",
            "Requirement already satisfied: gspread_dataframe in /usr/local/lib/python3.8/dist-packages (3.0.8)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from gspread) (2.25.1)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.8/dist-packages (from gspread) (2.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.2.1->gspread) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.2.1->gspread) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.2.1->gspread) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.2.1->gspread) (2022.12.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth->gspread) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth->gspread) (5.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth->gspread) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth->gspread) (0.4.8)\n"
          ]
        }
      ]
    }
  ]
}